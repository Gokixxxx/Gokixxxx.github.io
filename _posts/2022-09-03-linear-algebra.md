---
layout: post
title: 线性代数
subtitle: 用啥学啥。
tags: 数学
---

觉得应该开一个，所以就开了。

-----

特征多项式和零化多项式

经典应用是常系数齐次线性递推。特征多项式是$$\det(A-xI)$$，零化多项式是$$f(A)=0$$。cayley-hamilton定理说明特征多项式是一个零化多项式。

常系数齐次线性递推中，转移矩阵的特征多项式就是递推式，求这一矩阵的幂$$A^n$$，可以把它对零化多项式取膜，变成矩阵大小内的次数的线性组合这样的。

-----

特征向量和矩阵乘向量

如果一个矩阵的特征向量们是满秩的，那么它在乘一个向量的时候，可以把这个向量分解为特征向量的线性组合。

-----

jordan标准型

矩阵可以分解为$$A=PDP^{-1}$$，其中$$D$$是特征值组成的对角矩阵，$$P$$是特征向量按相同顺序组成的矩阵。计算特征向量可以直接代入特征值得到一个方程组，主要问题还是怎么求特征多项式的根(这不弱于因式分解)。

-----

stochastic matrix的无穷次幂

或译 马尔可夫矩阵。常见于概率期望相关dp或递推的转移矩阵。

这个题见于xix open cup gp of bytedance。这里是$$2\times 2$$的情况。进行jordan分解，由于特征多项式是二次的，而我们已经知道了一个根，所以就得到另一个，对于高次的，根可能在膜意义下不存在，需要扩域。

-----

幺模矩阵，格的三角基/hermite标准型

由一组向量的整系数线性组合得到的向量集合称为格。一组向量可以被消成一个hermite标准型，如果我们使用列向量，它大概就是一个下三角基。hermite标准型可以看成有限环线性基在所有整数上的推广。

幺模矩阵是行列式为$$\pm 1$$的矩阵。我们把一组向量拼成一个矩阵，那么乘一个幺模矩阵不改变它张成的格，因为幺模矩阵和矩阵乘法构成一个群，如果$$Ax=y$$，那么$$AUU^{-1}x=y$$，其中$$A$$是一组向量拼成的矩阵，$$x$$是一个系数向量，$$y$$是我们想要张出的向量，$$U$$是幺模的。

注意到，在gauss消元中用到的初等变换(把一行/列取负，交换两行/列，把一行/列的整数倍加到另一行/列)都是幺模的。所以我们可以进行辗转相除，但是很不幸，这会造成恐怖的中间表示膨胀，膨胀出来的东西的长度也是指数级的。

好消息是我们有一些办法。我们考虑对某些东西取膜，发现比如我们有$$m$$个向量，可以使用任何一个$$m\times m$$满秩子方阵的行列式的绝对值，设为$$d$$。把一个主对角线全是$$d$$的矩阵接在左边，那么我们每次进行一个操作之后，都可以用一次幺模的列变换给一个数取膜，具体可以看我画图，但是我还没画图，等我放假了我会画的/oh，不过你想看可能需要在放假的时候提醒我。

然后它的正确性在于我们可以用幺模变换把补的部分凑出来。设那个子方阵是$$A$$，那么根据伴随矩阵的结论有$$dA^{-1}$$是整数矩阵，并且它必然也是幺模的，所以有$$dAA^{-1}=dI$$，所以我们加的这些列必然可以由前面的列初等变换得到。选子方阵可以用有理数消一次，然后选择每个向量的第一个非零位所在的行，这个东西好像叫gram-schmidt orthogonalization。

现在考虑如果不满秩怎么做。我们把每一维当成一个向量，在上面消一下，最后只有若干维非零，对这些维跑上面的东西，然后根据消的时候的系数还原出剩下的维度即可。由于一个被消掉的维度必然是前面的维度在消它，所以这个东西确实是下三角的。这里和gram-schmidt是一致的。

但是这玩意中间用到的数长度还是太炸了，因为我们需要消一次，消一次，消一次，看起来只有矩阵大小实在是非常小的时候会用到它(比如poi2001 r1 A. superknight，二维的情况)。不过即便如此它还是很好的理论基础。

-----

lattice basic reduce, the lll algorithm

好像被认为是多元的exgcd，但是多数情况下还是挺没用吧。也许以后闲着没事会学，据说和椭球法有关。

